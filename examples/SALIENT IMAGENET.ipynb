{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R4 on Salient ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from models.R4_models import SalientImageNet, SeqSalientImageNet\n",
    "from models.pipeline import (train_model_with_certified_input_grad, train_model_with_pgd_robust_input_grad,\n",
    "                             accumulate_model_with_certified_input_grad, test_model_accuracy, test_delta_input_robustness,\n",
    "                             write_results_to_file, uniformize_magnitudes_schedule)\n",
    "from datasets import salient_imagenet\n",
    "from metrics import worst_group_acc, worst_group_acc_no_load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "SEED = 0\n",
    "DELTA_INPUT_ROBUSTNESS_PARAM = 1\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "torch.manual_seed(SEED)\n",
    "batch_size = 250\n",
    "test_batch_size = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/vol/bitbucket/mg2720/imagenet100_data\"\n",
    "MASKS_DIR = \"/vol/bitbucket/mg2720/salient_imagenet_dataset\"\n",
    "\n",
    "# train_imgnet = salient_imagenet.ImageNetDataset(DATA_DIR, MASKS_DIR, True)\n",
    "# test_imgnet = salient_imagenet.ImageNetDataset(DATA_DIR, MASKS_DIR, False)\n",
    "train_imgnet = salient_imagenet.LazyImageNetDataset(DATA_DIR, MASKS_DIR, True)\n",
    "test_imgnet = salient_imagenet.LazyImageNetDataset(DATA_DIR, MASKS_DIR, False)\n",
    "print(len(train_imgnet), len(test_imgnet))\n",
    "print(train_imgnet[0][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((train_imgnet[0][2]).shape)\n",
    "img, img_label, img_mask = None, None, None\n",
    "rand_5 = torch.randint(0, len(train_imgnet), (10,))\n",
    "for i in rand_5:\n",
    "    img, img_label, img_mask = train_imgnet[i]\n",
    "    if not torch.all(img_mask[0] == 0):\n",
    "        print(img_mask.shape[0])\n",
    "        print(img.shape)\n",
    "        print(torch.max(img), torch.min(img))\n",
    "        print(img_label)\n",
    "        fig, ax = plt.subplots(1, 2)\n",
    "        ax[0].imshow(img.float().permute(1, 2, 0).squeeze().numpy())\n",
    "        im_mask = ax[1].imshow(img_mask[0].numpy())\n",
    "        fig.colorbar(im_mask, ax=ax[1])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train = salient_imagenet.get_dataloader(train_imgnet, batch_size)\n",
    "dl_test = salient_imagenet.get_dataloader(test_imgnet, test_batch_size)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 6\n",
    "train_labels_per_class = [0] * num_classes\n",
    "for label_idx in range(num_classes):\n",
    "    train_labels_per_class[label_idx] = dl_train.dataset.label_tensors[dl_train.dataset.label_tensors == label_idx].shape[0]\n",
    "print(train_labels_per_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_root_save_dir = \"saved_experiment_models/performance/imagenet\"\n",
    "os.makedirs(model_root_save_dir, exist_ok=True)\n",
    "methods = [\"r4\", \"pgd_ex\", \"pgd_ex+r3\", \"std\", \"r3\", \"pgd_r4_pmo\", \"smooth_r3\", \"rand_r4_pmo\"]\n",
    "save_dir_for_method = {method: os.path.join(model_root_save_dir, method) for method in methods}\n",
    "for method in methods:\n",
    "    os.makedirs(save_dir_for_method[method], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_method = \"std\"\n",
    "# Hyperparameters\n",
    "num_epochs, lr, restarts, epsilon, k, weight_coeff = 6, 1e-4, 1, -1, -1, -1\n",
    "# k is a coefficient for the regularization term\n",
    "train_acc, test_acc = 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = SalientImageNet(6)\n",
    "    print(f\"========== Training model with method {std_method} restart {i} ==========\")\n",
    "    train_model_with_pgd_robust_input_grad(dl_train, num_epochs, curr_model, lr, criterion, epsilon, std_method, k, device)\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device, multi_class=True)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test, device, multi_class=True)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[std_method], f\"run_{i}.pt\"))\n",
    "    worst_group_acc_no_load(curr_model, dl_test, device, 6)\n",
    "empty_model = SalientImageNet(6)\n",
    "wg_acc, wg = worst_group_acc(empty_model, dl_test, device, 6, save_dir_for_method[std_method])\n",
    "write_results_to_file(\"experiment_results/imagenet.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 3),\n",
    "                       \"test_acc\": round(test_acc / restarts, 3),\n",
    "                       \"worst_group_acc\": round(wg_acc, 3),\n",
    "                       \"worst_group\": wg}, std_method)\n",
    "write_results_to_file(\"experiment_results/imagenet_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts}, std_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRR Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "rrr_method = \"r3\"\n",
    "num_epochs, lr, restarts, epsilon, k, weight_coeff = 5, 2e-4, 1, 0.1, 0.5, 1e-4\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = SalientImageNet(6)\n",
    "    print(f\"========== Training model with method {rrr_method} restart {i} ==========\")\n",
    "    train_model_with_pgd_robust_input_grad(dl_train, num_epochs, curr_model, lr, criterion, epsilon, rrr_method,\n",
    "        k, device, weight_reg_coeff=weight_coeff)\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device, multi_class=True)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test, device, multi_class=True)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[rrr_method], f\"run_{i}.pt\"))\n",
    "empty_model = SalientImageNet(6)\n",
    "wg_acc, wg = worst_group_acc(empty_model, dl_test, device, 6, save_dir_for_method[rrr_method])\n",
    "write_results_to_file(\"experiment_results/imagenet.yaml\",\n",
    "                        {\"train_acc\": round(train_acc / restarts, 3),\n",
    "                         \"test_acc\": round(test_acc / restarts, 3),\n",
    "                         \"worst_group_acc\": round(wg_acc / restarts, 3),\n",
    "                         \"worst_group\": wg}, rrr_method)\n",
    "write_results_to_file(\"experiment_results/imagenet_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,}, rrr_method)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4_method = \"r4\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "num_epochs, lr, restarts, epsilon, k, weight_coeff = 14, 2e-4, 3, 0.01, 0.01, -1\n",
    "train_acc, test_acc, num_robust, min_robust_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 1e+8, 0, 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = SalientImageNet(3, 6)\n",
    "    print(f\"========== Training model with method {r4_method} restart {i} ==========\")\n",
    "    train_model_with_certified_input_grad(dl_train, num_epochs, curr_model, lr, criterion, epsilon, r4_method,\n",
    "        k, device, True)\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device, multi_class=True)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test, device, multi_class=True)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(dl_test, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM,\n",
    "        \"cross_entropy\", device, has_conv=True)\n",
    "    num_robust += num_robust\n",
    "    min_robust_delta = min(min_robust_delta, min_delta)\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "write_results_to_file(\"experiment_results/imagenet.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 3),\n",
    "                       \"test_acc\": round(test_acc / restarts, 3),\n",
    "                       \"num_robust\": round(num_robust / restarts, 3),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 3),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 3),\n",
    "                       \"min_robust_delta\": min_robust_delta}, r4_method)\n",
    "write_results_to_file(\"experiment_results/imagenet_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"delta_threshold\": DELTA_INPUT_ROBUSTNESS_PARAM}, r4_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IBP-Ex Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/vol/bitbucket/mg2720/imagenet100_data\"\n",
    "masks_dir = \"/vol/bitbucket/mg2720/salient_imagenet_dataset\"\n",
    "train_dset = salient_imagenet.LazyImageNetDataset(data_dir, masks_dir, True)\n",
    "test_dset = salient_imagenet.LazyImageNetDataset(data_dir, masks_dir, False)\n",
    "dl_train = salient_imagenet.get_dataloader(train_dset, 10)\n",
    "num_dynamic_per_batch = 5\n",
    "dl_test = salient_imagenet.get_dataloader(test_dset, 25)\n",
    "ibp_ex = \"ibp_ex\"\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "num_epochs, lr, restarts, epsilon, k, weight_coeff = 13, 2e-4, 3, 0.01, 0.01, 2e-4\n",
    "train_acc, test_acc, num_robust, min_robust_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 1e+8, 0, 0\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = SalientImageNet(3, 6)\n",
    "    print(f\"========== Training model with method {ibp_ex} restart {i} ==========\")\n",
    "    accumulate_model_with_certified_input_grad(dl_train, num_epochs, curr_model, lr, criterion, epsilon, ibp_ex,\n",
    "        k, device, True, num_accs=num_dynamic_per_batch)\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device, multi_class=True)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test, device, multi_class=True)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(dl_test, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM,\n",
    "        \"cross_entropy\", device, has_conv=True)\n",
    "    num_robust += num_robust\n",
    "    min_robust_delta = min(min_robust_delta, min_delta)\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[ibp_ex], f\"model_{i}.pt\"))\n",
    "write_results_to_file(\"experiment_results/imagenet.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 3),\n",
    "                       \"test_acc\": round(test_acc / restarts, 3),\n",
    "                       \"num_robust\": round(num_robust / restarts, 3),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 3),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 3),\n",
    "                       \"min_robust_delta\": min_robust_delta}, ibp_ex)\n",
    "write_results_to_file(\"experiment_results/imagenet_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"delta_threshold\": DELTA_INPUT_ROBUSTNESS_PARAM}, ibp_ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
