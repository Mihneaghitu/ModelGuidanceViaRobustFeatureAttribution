{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Certified Finetuning of a Classifier on the OCT-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import torch\n",
    "import tqdm\n",
    "import abstract_gradient_training as agt\n",
    "from abstract_gradient_training import AGTConfig\n",
    "from abstract_gradient_training import certified_training_utils as ct_utils\n",
    "from models.deepmind import DeepMindSmall \n",
    "from datasets import oct_mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-train the model\n",
    "\n",
    "Exclude class 2 (Drusen) from the pretraining."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pre-training\n",
    "torch.manual_seed(1)\n",
    "device = torch.device(\"cuda:1\")\n",
    "pretrain_batchsize = 100\n",
    "pretrain_n_epochs = 20\n",
    "pretrain_learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model, dataset and optimizer\n",
    "model = DeepMindSmall(1, 1)\n",
    "dl_pretrain, _ = oct_mnist.get_dataloaders(pretrain_batchsize, exclude_classes=[2], balanced=True)\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=pretrain_learning_rate)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\".models/medmnist.ckpt\"):\n",
    "    model.load_state_dict(torch.load(\".models/medmnist.ckpt\"))\n",
    "else:  # pre-train the model\n",
    "    progress_bar = tqdm.trange(pretrain_n_epochs, desc=\"Epoch\", )\n",
    "    for epoch in progress_bar:\n",
    "        for i, (x, u) in enumerate(dl_pretrain):\n",
    "            # Forward pass\n",
    "            u, x = u.to(device), x.to(device)\n",
    "            output = model(x)\n",
    "            loss = criterion(output.squeeze().float(), u.squeeze().float())\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if i % 100 == 0:\n",
    "                progress_bar.set_postfix(loss=loss.item())\n",
    "    # save the model\n",
    "    with open(\".models/medmnist.ckpt\", \"wb\") as file:\n",
    "        torch.save(model.state_dict(), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tune the model on the private Drusen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up fine-tuning parameters\n",
    "batchsize = 5000\n",
    "config = AGTConfig(\n",
    "    fragsize=100,\n",
    "    learning_rate=0.1,\n",
    "    n_epochs=2,\n",
    "    k_private=10,\n",
    "    forward_bound=\"interval\",\n",
    "    device=\"cuda:1\",\n",
    "    backward_bound=\"interval\",\n",
    "    loss=\"binary_cross_entropy\",\n",
    "    clip_gamma=2.0,\n",
    "    # dp_sgd_sigma=0.1,\n",
    "    lr_decay=1.0,\n",
    "    lr_min=0.001,\n",
    "    log_level=\"DEBUG\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataloaders, train dataloader is a mix of drusen and the \"healthy\" class\n",
    "dl_train, _ = oct_mnist.get_dataloaders(batchsize, 1000, exclude_classes=[0, 1], balanced=True)\n",
    "_, dl_test_drusen = oct_mnist.get_dataloaders(batchsize, 1000, exclude_classes=[0, 1, 3])\n",
    "_, dl_test_other = oct_mnist.get_dataloaders(batchsize, 1000, exclude_classes=[2])\n",
    "_, dl_test_all = oct_mnist.get_dataloaders(batchsize, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Pre-trained model accuracy ===========\n",
      "Class 2 (Drusen) : nominal = 0.46\n",
      "Classes 0, 1, 3  : nominal = 0.96\n",
      "All Classes      : nominal = 0.84\n"
     ]
    }
   ],
   "source": [
    "# evaluate the pre-trained model\n",
    "param_n, param_l, param_u = ct_utils.get_parameters(model)\n",
    "drusen_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_drusen)), model, ct_utils.propagate_conv_layers)\n",
    "other_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_other)), model, ct_utils.propagate_conv_layers)\n",
    "all_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_all)), model, ct_utils.propagate_conv_layers)\n",
    "\n",
    "print(\"=========== Pre-trained model accuracy ===========\")\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}\")\n",
    "print(f\"Classes 0, 1, 3  : nominal = {other_acc[1]:.2g}\")\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [INFO    ] [00:07:55] =================== Starting Privacy Certified Training ===================\n",
      "[AGT] [DEBUG   ] [00:07:55] \tOptimizer params: n_epochs=2, learning_rate=0.1, l1_reg=0.0, l2_reg=0.0\n",
      "[AGT] [DEBUG   ] [00:07:55] \tLearning rate schedule: lr_decay=1.0, lr_min=0.001, early_stopping=True\n",
      "[AGT] [DEBUG   ] [00:07:55] \tPrivacy parameter: k_private=10\n",
      "[AGT] [DEBUG   ] [00:07:55] \tClipping: gamma=2.0, method=clamp\n",
      "[AGT] [DEBUG   ] [00:07:55] \tNoise: type=gaussian, sigma=0\n",
      "[AGT] [DEBUG   ] [00:07:55] \tBounding methods: forward=interval, loss=binary_cross_entropy, backward=interval\n",
      "[AGT] [INFO    ] [00:07:55] Starting epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[AGT] [DEBUG   ] [00:07:55] Initialising dataloader batchsize to 5000\n",
      "[AGT] [INFO    ] [00:07:55] Training batch 1: Network eval bounds=(0.46, 0.46, 0.46), W0 Bound=0.0 \n",
      "[AGT] [INFO    ] [00:07:57] Training batch 2: Network eval bounds=(0.66, 0.7 , 0.72), W0 Bound=0.461 \n",
      "[AGT] [INFO    ] [00:07:58] Training batch 3: Network eval bounds=(0.72, 0.77, 0.81), W0 Bound=0.696 \n",
      "[AGT] [DEBUG   ] [00:08:00] Skipping batch 4 in epoch 1 (expected batchsize 5000, got 508)\n",
      "[AGT] [INFO    ] [00:08:00] Starting epoch 2\n",
      "[AGT] [INFO    ] [00:08:00] Training batch 4: Network eval bounds=(0.72, 0.79, 0.84), W0 Bound=0.856 \n",
      "[AGT] [INFO    ] [00:08:01] Training batch 5: Network eval bounds=(0.7 , 0.8 , 0.87), W0 Bound=0.978 \n",
      "[AGT] [INFO    ] [00:08:03] Training batch 6: Network eval bounds=(0.69, 0.8 , 0.89), W0 Bound=1.08 \n",
      "[AGT] [DEBUG   ] [00:08:04] Skipping batch 4 in epoch 2 (expected batchsize 5000, got 508)\n",
      "[AGT] [INFO    ] [00:08:04] Final network eval: Network eval bounds=(0.67, 0.81, 0.91), W0 Bound=1.16 \n",
      "[AGT] [INFO    ] [00:08:04] =================== Finished Privacy Certified Training ===================\n"
     ]
    }
   ],
   "source": [
    "# fine-tune the model using abstract gradient training (keeping the convolutional layers fixed)\n",
    "param_l, param_n, param_u = agt.privacy_certified_training(\n",
    "    model, config, dl_train, dl_test_drusen, transform=ct_utils.propagate_conv_layers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Fine-tuned model accuracy + bounds ===========\n",
      "Class 2 (Drusen) : nominal = 0.81, certified bound = 0.67\n",
      "Classes 0, 1, 3  : nominal = 0.9, certified bound = 0.84\n",
      "All Classes      : nominal = 0.88, certified bound = 0.8\n",
      "======= Percentage of points with certified unlearning-safe guarantees =========\n",
      "Class 2 (Drusen) : 0.76\n",
      "Classes 0, 1, 3  : 0.89\n",
      "All Classes      : 0.85\n"
     ]
    }
   ],
   "source": [
    "# evaluate the fine-tuned model\n",
    "drusen_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_drusen)), model, ct_utils.propagate_conv_layers)\n",
    "other_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_other)), model, ct_utils.propagate_conv_layers)\n",
    "all_acc = agt.test_metrics.test_accuracy(param_n, param_l, param_u, *next(iter(dl_test_all)), model, ct_utils.propagate_conv_layers)\n",
    "\n",
    "print(\"=========== Fine-tuned model accuracy + bounds ===========\")\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}, certified bound = {drusen_acc[0]:.2g}\")\n",
    "print(f\"Classes 0, 1, 3  : nominal = {other_acc[1]:.2g}, certified bound = {other_acc[0]:.2g}\")\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}, certified bound = {all_acc[0]:.2g}\")\n",
    "\n",
    "# percentage of points with a certified unlearning-safe guarantee\n",
    "percent_certified_all = agt.test_metrics.proportion_certified(\n",
    "    param_n, param_l, param_u, *next(iter(dl_test_all)), model, ct_utils.propagate_conv_layers\n",
    ")\n",
    "percent_certified_drusen = agt.test_metrics.proportion_certified(\n",
    "    param_n, param_l, param_u, *next(iter(dl_test_drusen)), model, ct_utils.propagate_conv_layers\n",
    ")\n",
    "percent_certified_other = agt.test_metrics.proportion_certified(\n",
    "    param_n, param_l, param_u, *next(iter(dl_test_other)), model, ct_utils.propagate_conv_layers\n",
    ")\n",
    "print(f\"======= Percentage of points with certified unlearning-safe guarantees =========\")\n",
    "print(f\"Class 2 (Drusen) : {percent_certified_drusen:.2g}\")\n",
    "print(f\"Classes 0, 1, 3  : {percent_certified_other:.2g}\")\n",
    "print(f\"All Classes      : {percent_certified_all:.2g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========== Fine-tuned model accuracy + bounds ===========\n",
      "Class 2 (Drusen) : nominal = 0.8, certified bound = 0.68\n",
      "Classes 0, 1, 3  : nominal = 0.87, certified bound = 0.81\n",
      "All Classes      : nominal = 0.85, certified bound = 0.77\n"
     ]
    }
   ],
   "source": [
    "# make private predictions\n",
    "noise_level = 1.0 / 5.0\n",
    "drusen_acc = agt.test_metrics.test_accuracy(\n",
    "    param_n,\n",
    "    param_l,\n",
    "    param_u,\n",
    "    *next(iter(dl_test_drusen)),\n",
    "    model,\n",
    "    ct_utils.propagate_conv_layers,\n",
    "    noise_level=noise_level,\n",
    ")\n",
    "other_acc = agt.test_metrics.test_accuracy(\n",
    "    param_n, param_l, param_u, *next(iter(dl_test_other)), model, ct_utils.propagate_conv_layers, noise_level=noise_level\n",
    ")\n",
    "all_acc = agt.test_metrics.test_accuracy(\n",
    "    param_n, param_l, param_u, *next(iter(dl_test_all)), model, ct_utils.propagate_conv_layers, noise_level=noise_level\n",
    ")\n",
    "\n",
    "print(\"=========== Fine-tuned model accuracy + bounds ===========\")\n",
    "print(f\"Class 2 (Drusen) : nominal = {drusen_acc[1]:.2g}, certified bound = {drusen_acc[0]:.2g}\")\n",
    "print(f\"Classes 0, 1, 3  : nominal = {other_acc[1]:.2g}, certified bound = {other_acc[0]:.2g}\")\n",
    "print(f\"All Classes      : nominal = {all_acc[1]:.2g}, certified bound = {all_acc[0]:.2g}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
