{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R4 on ISIC 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import numpy as np\n",
    "from models.R4_models import LesionNet\n",
    "from models.pipeline import (train_model_with_certified_input_grad, train_model_with_pgd_robust_input_grad, write_results_to_file,\n",
    "                             test_model_avg_and_wg_accuracy, train_model_with_smoothed_input_grad, test_model_accuracy,\n",
    "                             test_delta_input_robustness, test_model_avg_and_wg_accuracy)\n",
    "from metrics import (get_restart_avg_and_worst_group_accuracy_with_stddev, get_restart_macro_avg_acc_over_labels_with_stddev)\n",
    "from datasets import isic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: for ISIC, we need to separately calculate the macro averaged accuracy over the LABELS, because the groups differ from the labels in this dataset, i.e.: labels are 0 and 1 (benign and malignant), while the groups are 0, 1 and 2 representing (\"cancer\", \"no patch no cancer\" and \"patch no cancer\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the dataloaders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=1\n",
    "SEED = 0\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "criterion = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = \"/vol/bitbucket/mg2720/isic/\"\n",
    "\n",
    "isic_train = isic.ISICDataset(DATA_ROOT, is_train=True)\n",
    "isic_test = isic.ISICDataset(DATA_ROOT, is_train=False)\n",
    "isic_test_grouped = isic.ISICDataset(DATA_ROOT, is_train=False, grouped=True)\n",
    "img, lbl, mask = isic_train[1]\n",
    "train_pos, train_neg = (isic_train.labels == 1).sum(), (isic_train.labels == 0).sum()\n",
    "print(f\"Train: {train_pos} positive, {train_neg} negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "for i in range(len(isic_train)):\n",
    "    img, lbl, mask = isic_train[i]\n",
    "    if mask.sum() > 0:\n",
    "        idx = i\n",
    "        break\n",
    "plt.imshow(img.permute(1, 2, 0).squeeze().numpy())\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "print(mask.shape, mask.sum())\n",
    "plt.imshow(mask.permute(1, 2, 0).squeeze().numpy())\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dl_train = isic.get_loader_from_dataset(isic_train, batch_size=batch_size, shuffle=False)\n",
    "dl_test = isic.get_loader_from_dataset(isic_test, batch_size=batch_size, shuffle=False)\n",
    "dl_test_grouped = isic.get_loader_from_dataset(isic_test_grouped, batch_size=50, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA_INPUT_ROBUSTNESS_PARAM = 1\n",
    "model_root_save_dir = \"saved_experiment_models/performance/isic\"\n",
    "os.makedirs(model_root_save_dir, exist_ok=True)\n",
    "methods = [\"r4\", \"pgd_r4\", \"std\", \"smooth_r3\", \"rand_r4\", \"ibp_ex\", \"ibp_ex+r3\", \"r3\"]\n",
    "save_dir_for_method = {method: os.path.join(model_root_save_dir, method) for method in methods}\n",
    "for method in methods:\n",
    "    os.makedirs(save_dir_for_method[method], exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_method = \"std\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k = 8, 0.0003, 3, 0.1, -1, -1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {std_method} restart {i} ==========\")\n",
    "    train_model_with_certified_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, std_method, k, device, True, class_weights = class_weights\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[std_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[std_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[std_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, std_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, std_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RRR Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rrr_method = \"r3\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k = 10, 0.0003, 3, 0.1, -1, 0.1\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {rrr_method} restart {i} ==========\")\n",
    "    train_model_with_pgd_robust_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, rrr_method, k, device, True, class_weights = class_weights\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[rrr_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[rrr_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[rrr_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, rrr_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, rrr_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothed-R3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_r3_method = \"smooth_r3\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, weight_decay, restarts, epsilon, k, num_samples = 14, 0.0007, 1e-5, 3, 0.1, 0.1, 3\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {smooth_r3_method} restart {i} ==========\")\n",
    "    train_model_with_smoothed_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, smooth_r3_method, k, device, weight_decay=weight_decay,\n",
    "        class_weights = class_weights, num_samples=num_samples\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[smooth_r3_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, _, std_dev_wg = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[smooth_r3_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, std_dev_labels = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[smooth_r3_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"std_dev_over_labels\": round(std_dev_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"std_dev_worst_group\": round(std_dev_wg, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, smooth_r3_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_decay\": weight_decay,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"num_samples\": num_samples,\n",
    "                         \"with_k_schedule\": False}, smooth_r3_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBP-Ex Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibp_ex_method = \"ibp_ex\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k = 12, 0.001, 3, 0.2, 5e-5, 0.3\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {ibp_ex_method} restart {i} ==========\")\n",
    "    train_model_with_certified_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, ibp_ex_method, k, device, True, class_weights = class_weights\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[ibp_ex_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[ibp_ex_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[ibp_ex_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, ibp_ex_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, ibp_ex_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBP-Ex+R3 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibp_ex_and_r3_method = \"ibp_ex+r3\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k = 14, 0.001, 3, 0.25, 1e-4, 0.325\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {ibp_ex_and_r3_method} restart {i} ==========\")\n",
    "    train_model_with_certified_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, ibp_ex_and_r3_method, k, device, True, class_weights = class_weights\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[ibp_ex_and_r3_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[ibp_ex_and_r3_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[ibp_ex_and_r3_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, ibp_ex_and_r3_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, ibp_ex_and_r3_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4_method = \"r4\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k, weight_decay = 25, 0.001, 3, 0.3, -1, 1, 1e-4\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {r4_method} restart {i} ==========\")\n",
    "    train_model_with_certified_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, r4_method, k, device, True,\n",
    "        class_weights=class_weights, weight_decay=weight_decay\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[r4_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[r4_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[r4_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, r4_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"multi_class\": False,\n",
    "                         \"weight_decay\": weight_decay,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, r4_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PGD-R4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pgd_r4_method = \"pgd_r4\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k, weight_decay = 25, 0.0008, 3, 0.1, 1e-5, 0.0005, 1e-4\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {pgd_r4_method} restart {i} ==========\")\n",
    "    train_model_with_pgd_robust_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, pgd_r4_method, k, device, True,\n",
    "        class_weights=class_weights, weight_decay=weight_decay, num_iterations=5\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[pgd_r4_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, *_ = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[pgd_r4_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, _ = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[pgd_r4_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, pgd_r4_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"weight_decay\": weight_decay,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"with_k_schedule\": False}, pgd_r4_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rand-R4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_r4_method = \"rand_r4\"\n",
    "# hyperparameters\n",
    "class_weights = [1, 9]\n",
    "num_epochs, lr, restarts, epsilon, weight_coeff, k, weight_decay, num_samples = 25, 0.0008, 3, 0.1, 1e-5, 0.0007, 1e-4, 3\n",
    "test_epsilon = 0.1\n",
    "# Train standard 3 times and test accuracy and delta input robustness for the masked region\n",
    "train_acc, test_acc, num_robust, avg_delta, min_lower_bound, max_upper_bound = 0, 0, 0, 0, 0, 0\n",
    "for i in range(restarts):\n",
    "    # Reinitialize the model\n",
    "    # We could try to just reinitialize the weights, but we can throw away the previous model for now as we do not need it\n",
    "    torch.manual_seed(i + SEED)\n",
    "    curr_model = LesionNet(3, 1).to(device)\n",
    "\n",
    "    print(f\"========== Training model with method {rand_r4_method} restart {i} ==========\")\n",
    "    train_model_with_smoothed_input_grad(\n",
    "        dl_train, num_epochs, curr_model, lr, criterion, epsilon, rand_r4_method, k, device,\n",
    "        class_weights=class_weights, weight_decay=weight_decay, num_samples=num_samples\n",
    "    )\n",
    "    print(\"Testing model accuracy for the training set\")\n",
    "    train_acc += test_model_accuracy(curr_model, dl_train, device)\n",
    "    print(\"Testing model accuracy for the test set\")\n",
    "    test_acc += test_model_accuracy(curr_model, dl_test_grouped, device)\n",
    "    n_r, min_delta, m_l, m_u = test_delta_input_robustness(\n",
    "        dl_test_grouped, curr_model, epsilon, DELTA_INPUT_ROBUSTNESS_PARAM, \"binary_cross_entropy\", device, has_conv=True\n",
    "    )\n",
    "    num_robust += num_robust\n",
    "    avg_delta += min_delta\n",
    "    min_lower_bound += m_l\n",
    "    max_upper_bound += m_u\n",
    "    avg_g_acc, wg_acc, wg = test_model_avg_and_wg_accuracy(curr_model, dl_test_grouped, device, num_groups=3)\n",
    "    torch.save(curr_model.state_dict(), os.path.join(save_dir_for_method[rand_r4_method], f\"run_{i}.pt\"))\n",
    "empty_model = LesionNet(3, 1).to(device)\n",
    "avg_acc, wg_acc, wg, _, std_dev_wg = get_restart_avg_and_worst_group_accuracy_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[rand_r4_method], empty_model, device, num_groups=3\n",
    ")\n",
    "macro_avg_over_labels, std_dev_all = get_restart_macro_avg_acc_over_labels_with_stddev(\n",
    "    dl_test_grouped, save_dir_for_method[rand_r4_method], empty_model, device, num_classes=2\n",
    ")\n",
    "write_results_to_file(\"experiment_results/isic.yaml\",\n",
    "                      {\"train_acc\": round(train_acc / restarts, 5),\n",
    "                       \"test_acc\": round(test_acc / restarts, 5),\n",
    "                       \"avg_group_acc\": round(avg_acc, 5),\n",
    "                       \"macro_avg_over_labels\": round(macro_avg_over_labels, 5),\n",
    "                       \"std_dev_over_labels\": round(std_dev_all, 5),\n",
    "                       \"worst_group_acc\": round(wg_acc, 5),\n",
    "                       \"std_dev_wg\": round(std_dev_wg, 5),\n",
    "                       \"worst_group\": wg,\n",
    "                       \"min_robust_delta\": round(avg_delta / restarts, 5),\n",
    "                       \"min_lower_bound\": round(min_lower_bound / restarts, 5),\n",
    "                       \"max_upper_bound\": round(max_upper_bound / restarts, 5)\n",
    "                       }, rand_r4_method)\n",
    "write_results_to_file(\"experiment_results/isic_params.yaml\",\n",
    "                        {\"epsilon\": epsilon,\n",
    "                         \"test_epsilon\": test_epsilon,\n",
    "                         \"k\": k,\n",
    "                         \"weight_coeff\": weight_coeff,\n",
    "                         \"num_epochs\": num_epochs,\n",
    "                         \"lr\": lr,\n",
    "                         \"restarts\": restarts,\n",
    "                         \"train_batch_size\": dl_train.batch_size,\n",
    "                         \"test_batch_size\": dl_train.batch_size,\n",
    "                         \"class_weights\": class_weights,\n",
    "                         \"weight_decay\": weight_decay,\n",
    "                         \"multi_class\": False,\n",
    "                         \"has_conv\": True,\n",
    "                         \"num_samples\": num_samples,\n",
    "                         \"with_k_schedule\": False}, rand_r4_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fypvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
